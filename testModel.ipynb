{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import tiktoken\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    # Encodes the text using GPT-2 tokenizer\n",
    "    return tokenizer.encode_ordinary(text)\n",
    "\n",
    "def decode(tokens):\n",
    "    # Decodes the token IDs back to text\n",
    "    return tokenizer.decode(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = ort.InferenceSession('./hg1.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"What\"\n",
    "tokenized_input = encode(input_text)  # Use the same encode function as before\n",
    "input_data = np.array(tokenized_input, dtype=np.int64).reshape(1, -1)  # Reshape with batch size 1\n",
    "input_name = session.get_inputs()[0].name\n",
    "final_tokens = encode(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(500):\n",
    "    output = session.run(None, {input_name: input_data})\n",
    "    # Get logits for the last position and compute probabilities\n",
    "    logits = output[0][0, -1, :]\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits))\n",
    "\n",
    "    # Choose from the top 5 most probable tokens\n",
    "    top_5_indices = np.argsort(probabilities)[-5:]\n",
    "    top_5_probs = probabilities[top_5_indices]\n",
    "    top_5_probs /= np.sum(top_5_probs)  # Normalize probabilities of top 5 tokens\n",
    "\n",
    "    # Randomly select one of the top 5 tokens\n",
    "    last_token = np.random.choice(top_5_indices, p=top_5_probs)\n",
    "    # Append the selected token to the input for the next iteration\n",
    "    tokenized_input.append(last_token)\n",
    "    if len(tokenized_input)>128:\n",
    "        tokenized_input = tokenized_input[-128:]\n",
    "    final_tokens.append(last_token)\n",
    "    input_data = np.array(tokenized_input, dtype=np.int64).reshape(1, -1)  # Reshape with batch size 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What? I am doing to kill him? I\n",
      "do not know what I do. I am not know what I am doing to him.\n",
      "\"I'll get to the Capitol,\" he says. \"And you think I\n",
      "still have a piece in your district in District Twelve?\" \"Yes. But you are not your district. So do not have a secret's really know what your money for the reaping,\" says Peeta.\n",
      "\"I mean, too,\" says Haymitch. \"I do not think I\n",
      "would never be. I'll never have to. I\n",
      "would never have to be. If I had not have to get it, he'd be able to get it.\" I do not know what Haymitch doesn't need to say.\n",
      "He's right. \"I am not going on a lot of stuff you. I am not going to be stupid.\" \"No,\" I say. I have to be a squirrels says, and my mother's too. \"Well, you are still warm.\" \"Not if I have to, I have got a goat.\" I do not know what. I do not know. I do. \"I'll just go down to that. I have got a squirrel and add something.\" \"Well, it's just as I have to tell Rue about it. It's a little cooler though.\" Rue's not enough. I take a sound.\n",
      "\"I have to show you,\" she says.\n",
      "\"I'll find the food,\" I tell her. \"But you.\" She neatly unhooks herself and sunset,\" she says.\n",
      "\"You are not going to be okay?\" I say.\n",
      "\"No, I'll be not,\" says.\n",
      "\"But I'll get it back,\" says Rue.\n",
      "I hardly a few pairs of eyes.\n",
      "\"You'll have to eat,\" I say. I can see Beetee. \"I am not sure they can. If I'll have to get a few days,\" says Rue.\n",
      "\"They are so I can do,\" says Rue.\n",
      "\"But you'll get to the sun go down with that in your leg. But you'll be too.\" She neatly returns to a handful of berries.\n",
      "\"I want them for the sleeping bag,\" I say.\n",
      "\"I'll be safe,\" she says.\n",
      "\"I'll be so.\" \"Not if we'll go to the lake,\" says. We divide the stream. I\n"
     ]
    }
   ],
   "source": [
    "print(decode(final_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
